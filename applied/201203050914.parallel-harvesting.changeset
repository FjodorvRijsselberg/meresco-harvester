Changeset created on Mon Mar 05 09:14:38 UTC 2012 by Seecr (Seek You Too B.V.)

Description: Parallel harvesting of repositories

    Repositories can now be harvested parallel. This can be done using the 
    --concurrency option.Default it will be harvesting just 1 repository.

    To make parallel harvesting more usefull, the harvester script never stops 
    but starts from the beginning if all repositories are harvested. Only if 
    --runOnce is given it will stop after processing all repositories.

Baseline version: https://meresco.svn.sourceforge.net/svnroot/meresco/meresco-harvester/workingsets/7.3.3-Edurep/version_0

diff --unidirectional-new-file --recursive --unified '--exclude=*.so' '--exclude=*.o' '--exclude=.svn' '--exclude=*.pyc' '--exclude=deps.d' '--exclude=applied' version_0/meresco/harvester/eventlogger.py /home/hendrik/development/meresco/meresco-harvester/workingsets/7.3.3-Edurep/version_1/meresco/harvester/eventlogger.py
--- version_0/meresco/harvester/eventlogger.py	2012-02-28 08:47:24.000000000 +0100
+++ version_1/meresco/harvester/eventlogger.py	2012-03-05 10:14:31.000000000 +0100
@@ -36,13 +36,16 @@
 from datetime import datetime
 from cStringIO import StringIO
 from os.path import dirname, isdir
-from os import makedirs
+from os import makedirs, rename
 
 LOGLINE_RE=compile(r'^\[([^\]]*)\]\t([\w ]+)\t\[([^\]]*)\]\t(.*)$')
 
 class BasicEventLogger(object):
-    def __init__(self, logfile):
-        self._logfile = self._openlogfile(logfile)
+    def __init__(self, logfile, maxLogLines=20000):
+        self._numberOfLogLines = 0
+        self._maxLogLines = maxLogLines
+        self._logfilePath = logfile
+        self._logfile = self._openlogfile(self._logfilePath)
 
     def close(self):
         if self._logfile:
@@ -58,6 +61,7 @@
         self._space()
         self._comments(comments)
         self._flush()
+        self._clearExcessLogLines()
 
     def _time(self):
         now = datetime.utcnow()
@@ -89,12 +93,32 @@
         return self
 
 class EventLogger(BasicEventLogger):
-    def __init__(self,logfile):
-        BasicEventLogger.__init__(self, logfile)
+    def __init__(self, logfile, maxLogLines=20000):
+        BasicEventLogger.__init__(self, logfile, maxLogLines=maxLogLines)
 
     def _openlogfile(self, logfile):
+        self._numberOfLogLines = 0
         isdir(dirname(logfile)) or makedirs(dirname(logfile))
-        return open(logfile, 'a+')
+        f = open(logfile, 'a+')
+        for line in f:
+            self._numberOfLogLines += 1
+        return f
+
+    def _clearExcessLogLines(self):
+        if self._numberOfLogLines >= self._maxLogLines:
+            self._logfile.seek(0)
+            tmpFile = open(self._logfilePath + ".tmp", 'w')
+            for i, line in enumerate(self._logfile):
+                if i >= self._maxLogLines / 2:
+                    tmpFile.write(line)
+            tmpFile.close()
+            self.close()
+            rename(self._logfilePath + ".tmp", self._logfilePath)
+            self._logfile = self._openlogfile(self._logfilePath)
+
+    def logLine(self, *args, **kwargs):
+        self._numberOfLogLines += 1
+        BasicEventLogger.logLine(self, *args, **kwargs)
 
     def logSuccess(self,comments='', id=''):
         self.logLine('SUCCES', comments=comments, id=id)
@@ -120,6 +144,9 @@
     def _openlogfile(self, logfile):
         return self._stream
 
+    def _clearExcessLogLines(self):
+        pass
+
 class CompositeLogger(EventLogger):
     def __init__(self, loggers):
         EventLogger.__init__(self, None)
@@ -128,6 +155,9 @@
     def _openlogfile(self, logfile):
         return None
 
+    def _clearExcessLogLines(self):
+        pass
+
     def logLine(self, event, comments, id=''):
         for events, logger in self._loggers:
             if events == ['*'] or event in events:
@@ -140,6 +170,9 @@
         def _openlogfile(self, logfile):
             pass
 
+        def _clearExcessLogLines(self):
+            pass
+
         def logLine(self, event, comments, id=''):
             pass
 
diff --unidirectional-new-file --recursive --unified '--exclude=*.so' '--exclude=*.o' '--exclude=.svn' '--exclude=*.pyc' '--exclude=deps.d' '--exclude=applied' version_0/meresco/harvester/startharvester.py /home/hendrik/development/meresco/meresco-harvester/workingsets/7.3.3-Edurep/version_1/meresco/harvester/startharvester.py
--- version_0/meresco/harvester/startharvester.py	2012-02-28 14:47:36.000000000 +0100
+++ version_1/meresco/harvester/startharvester.py	2012-03-05 10:14:31.000000000 +0100
@@ -40,8 +40,12 @@
 from timedprocess import TimedProcess
 from urllib import urlopen
 from os.path import join
+from select import select, error
 from sys import stderr, stdout, exit, argv
 from optparse import OptionParser
+from os import read
+from signal import SIGINT
+from errno import EBADF, EINTR, EAGAIN
 
 AGAIN_EXITCODE = 42
 
@@ -54,7 +58,9 @@
         self.__dict__.update(args.__dict__)
 
         if not self.domainId:
-            self.parser.logError("Specify domain")
+            self.parser.error("Specify domain")
+        if self._concurrency < 1:
+            self.parser.error("Concurrency must be at least 1.")
 
         if self._logDir == None:
             self._logDir = urlopen(self.saharaurl + '/_getoptions/logDir').read()
@@ -95,6 +101,12 @@
             help="Override the stateDir in the apache configuration.", 
             metavar="DIRECTORY", 
             default=None)
+        self.parser.add_option("--concurrency", 
+            dest="_concurrency",
+            type="int",
+            default=1,
+            help="Number of repositories to be concurrently harvested. Defaults to 1 (no concurrency).", 
+            metavar="NUMBER")
         self.parser.add_option("--force-target", "", 
             dest="forceTarget",
             help="Overrides the repository's target", 
@@ -114,47 +126,103 @@
             action="store_true",
             default=False,
             help="Prevent harvester from looping (if combined with --repository)")
+        self.parser.add_option("--child", "",
+            action="store_true",
+            dest="child",
+            default=False,
+            help="Option set by harvester. Never do this by yourself.")
 
         (options, args) = self.parser.parse_args()
         return options
 
     def start(self):
-        if not self.repository:
-            self._restartWithLoop()
-        elif not self.runOnce:
-            self._startRepositoryWithChild()
-        else:
+        self._childProcesses = []
+        if self.child:
             self._startRepository()
+        elif self.repository:
+            self._startOne()
+        else:
+            self._startAll()
 
-    def _restartWithLoop(self):
+    def _startAll(self):
         for key in self.saharaget.getRepositoryIds(self.domainId):
-            self._startChildProcess(['--repository='+key, '--runOnce'])
+            self._childProcesses.append(self._createArgs(['--repository='+key]))
+        self._startChildProcesses()
 
-    def _startRepositoryWithChild(self):
-        self._startChildProcess(['--runOnce'])
-
-    def _startChildProcess(self, extraArgs):
-        args = argv[:1] + extraArgs + argv[1:]
-        exitstatus = AGAIN_EXITCODE
-        while exitstatus == AGAIN_EXITCODE:
-            t = TimedProcess()
-            try:
-                SIG_INT = 2
-                exitstatus = t.executeScript(args, self.processTimeout, SIG_INT)
-            except KeyboardInterrupt, e:
+    def _startOne(self):
+        self._childProcesses.append(self._createArgs(extraArgs=[]))
+        self._startChildProcesses()
+
+    def _startChildProcesses(self):
+        processes = {}
+        try:
+            for i in range(min(self._concurrency, len(self._childProcesses))):
+                args = self._childProcesses.pop(0)
+                t, process = self._createProcess(args)
+                processes[process.stdout.fileno()] = t, process, args
+                processes[process.stderr.fileno()] = t, process, args
+            while processes:
+                try:
+                    readers, _, _ = select(processes.keys(), [], [])
+                except error, (errno, description):
+                    if errno == EINTR:
+                        pass
+                    else:
+                        raise
+                for reader in readers:
+                    if reader not in processes:
+                        continue
+
+                    t, process, args = processes[reader]
+                    try:
+                        pipeContent = read(reader, 4096)
+                    except OSError, e:
+                        if e.errno == EAGAIN:
+                            continue
+                        raise
+                    if reader == process.stdout.fileno():
+                        stdout.write(pipeContent)
+                        stdout.flush()
+                    else:
+                        stderr.write(pipeContent)
+                        stderr.flush()
+
+                    if process.poll() is not None:
+                        exitstatus = t.stopScript(process)
+                        del processes[process.stdout.fileno()]
+                        del processes[process.stderr.fileno()]
+                        if exitstatus == AGAIN_EXITCODE:
+                            self._childProcesses.insert(0, args)
+                        else:
+                            if exitstatus != 0:
+                                stderr.write("Process (with args: %s) exited with exitstatus %s.\n" % (args, exitstatus))
+                                stderr.flush()
+                            if not self.runOnce:
+                                self._childProcesses.append(args)
+                        if len(self._childProcesses) > 0:
+                            newArgs = self._childProcesses.pop(0)
+                            t, process = self._createProcess(newArgs)
+                            processes[process.stdout.fileno()] = t, process, newArgs
+                            processes[process.stderr.fileno()] = t, process, newArgs
+        except:
+            for t in set([t for t,process,args in processes.values()]):
                 t.terminate()
-                raise
+            raise
 
+    def _createProcess(self, args):
+        t = TimedProcess()
+        return t, t.executeScript(args, self.processTimeout, SIGINT)
 
-    def _startRepository(self):
+    def _createArgs(self, extraArgs):
+        return argv[:1] + ["--child"] + extraArgs + argv[1:]
 
+    def _startRepository(self):
         if self.forceTarget:
             self.repository.targetId = self.forceTarget
         if self.forceMapping:
             self.repository.mappingId = self.forceMapping
 
         self._generalHarvestLog = CompositeLogger([
-            (['*'], EventLogger(join(self._logDir, self.domainId, 'harvester.log'))),
             (['*'], StreamEventLogger(stdout)),
             (['ERROR', 'WARN'], StreamEventLogger(stderr)),
         ])
diff --unidirectional-new-file --recursive --unified '--exclude=*.so' '--exclude=*.o' '--exclude=.svn' '--exclude=*.pyc' '--exclude=deps.d' '--exclude=applied' version_0/meresco/harvester/timedprocess.py /home/hendrik/development/meresco/meresco-harvester/workingsets/7.3.3-Edurep/version_1/meresco/harvester/timedprocess.py
--- version_0/meresco/harvester/timedprocess.py	2012-02-28 08:47:24.000000000 +0100
+++ version_1/meresco/harvester/timedprocess.py	2012-03-05 10:14:31.000000000 +0100
@@ -32,9 +32,10 @@
 # 
 ## end license ##
 
-from os import waitpid, kill, P_NOWAIT
-from subprocess import Popen
+from os import waitpid, kill, P_NOWAIT, O_NONBLOCK
+from subprocess import Popen, PIPE
 from sys import executable
+from fcntl import fcntl, F_SETFL
 
 from threading import Timer
 
@@ -63,17 +64,17 @@
 
     def executeScript(self, args, timeout, signal=9):
         self._signal = signal
-        process = Popen(args)
+        process = Popen(args, stdout=PIPE, stderr=PIPE, bufsize=0)
+        fcntl(process.stdout.fileno(), F_SETFL, O_NONBLOCK)
         self._pid = process.pid
         self.timer = Timer(timeout, self.terminate)
         self.timer.start()
-        resultpid, status = waitpid(self._pid, 0)
-        exitstatus = status >> 8
+        return process
 
+    def stopScript(self, process):
         if not self._wasTimeout:
             self.timer.cancel()
             self._wasSuccess = True
             self._wasTimeout = False
-
-        return exitstatus 
+        return process.returncode
 
diff --unidirectional-new-file --recursive --unified '--exclude=*.so' '--exclude=*.o' '--exclude=.svn' '--exclude=*.pyc' '--exclude=deps.d' '--exclude=applied' version_0/test/eventloggertest.py /home/hendrik/development/meresco/meresco-harvester/workingsets/7.3.3-Edurep/version_1/test/eventloggertest.py
--- version_0/test/eventloggertest.py	2012-02-28 08:47:24.000000000 +0100
+++ version_1/test/eventloggertest.py	2012-03-05 10:14:31.000000000 +0100
@@ -143,3 +143,22 @@
         comp.logError('error', 'id')
         self.assertEquals('ERROR\t[id]\terror\n', stream1.getvalue()[DATELENGTH:])
         self.assertEquals('ERROR\t[id]\terror\n', stream2.getvalue()[DATELENGTH:])
+
+    def testClearLogfile(self):
+        self.logger.logLine('SUCCES','Some logline 1')
+        self.logger.close()
+        self.logger = EventLogger(EVENTLOGFILE, maxLogLines=4)
+        self.logger.logLine('SUCCES','Some logline 2')
+        self.logger.logLine('SUCCES','Some logline 3')
+        self.logger.logLine('SUCCES','Some logline 4')
+        logfile = open(EVENTLOGFILE,'r+')
+        self.assertEquals('SUCCES\t[]\tSome logline 3', logfile.readline().strip()[DATELENGTH:])
+
+        self.logger.logLine('SUCCES','Some logline 5')
+        logfile = open(EVENTLOGFILE,'r+')
+        self.assertEquals('SUCCES\t[]\tSome logline 3', logfile.readline().strip()[DATELENGTH:])
+
+        self.logger.logLine('SUCCES','Some logline 6')
+        logfile = open(EVENTLOGFILE,'r+')
+        self.assertEquals('SUCCES\t[]\tSome logline 5', logfile.readline().strip()[DATELENGTH:])
+
diff --unidirectional-new-file --recursive --unified '--exclude=*.so' '--exclude=*.o' '--exclude=.svn' '--exclude=*.pyc' '--exclude=deps.d' '--exclude=applied' version_0/test/integration/harvestertest.py /home/hendrik/development/meresco/meresco-harvester/workingsets/7.3.3-Edurep/version_1/test/integration/harvestertest.py
--- version_0/test/integration/harvestertest.py	2012-02-28 08:47:24.000000000 +0100
+++ version_1/test/integration/harvestertest.py	2012-03-05 10:14:31.000000000 +0100
@@ -29,7 +29,7 @@
 ## end license ##
 from __future__ import with_statement
 
-from os import system, waitpid, listdir
+from os import system, waitpid, listdir, remove, kill
 from os.path import join, dirname, abspath
 from urllib import urlopen
 from time import time, sleep
@@ -71,6 +71,9 @@
         repo.maximumIgnore = '5'
         repo.save(self.repofilepath)
 
+    def tearDown(self):
+        remove(self.repofilepath)
+
     def testHarvestToSruUpdate(self):
         # initial harvest
         self.startHarvester(repository=REPOSITORY)
@@ -351,6 +354,65 @@
         ids = open(join(self.harvesterStateDir, DOMAIN, "%s.ids" % REPOSITORY)).readlines()
         self.assertEquals(0, len(ids), ids)
 
+    def testConcurrentHarvestToSruUpdate(self):
+        self.startHarvester(concurrency=3)
+
+        requestsLogged = sorted(listdir(self.dumpDir))
+
+        repositoryIds = []
+        for f in requestsLogged:
+            lxml = parse(open(join(self.dumpDir, f)))
+            repositoryIds.append(xpath(lxml, '//ucp:recordIdentifier/text()')[0].split(':', 1)[0])
+
+        repositoryIdsSet = set(repositoryIds)
+        self.assertEquals(set(['repository2', 'integrationtest', 'harvestertest']), repositoryIdsSet)
+
+        lastSeenRepoId = None
+        try:
+            for repo in repositoryIds:
+                if repo != lastSeenRepoId:
+                    repositoryIdsSet.remove(repo)
+                    lastSeenRepoId = repo
+                    continue
+        except KeyError:
+            pass
+        else:
+            self.fail('Records should have been inserted out-of-order.')
+
+    def testConcurrentHarvestToSruUpdateBUG(self):
+        r = RepositoryData.read(self.repofilepath)
+        r.complete = 'true'
+        r.save(self.repofilepath)
+        self.startHarvester(concurrency=1)
+
+        requestsLogged = sorted(listdir(self.dumpDir))
+        repositoryIds = []
+        for f in requestsLogged:
+            lxml = parse(open(join(self.dumpDir, f)))
+            repositoryIds.append(xpath(lxml, '//ucp:recordIdentifier/text()')[0].split(':', 1)[0])
+        self.assertEquals(15, repositoryIds.count(REPOSITORY))
+        self.assertEquals(10, repositoryIds.count('repository2'))
+        self.assertEquals(10, repositoryIds.count('integrationtest'))
+
+    def testConcurrencyAtLeastOne(self):
+        stdouterrlog = self.startHarvester(concurrency=0)
+        self.assertTrue("Concurrency must be at least 1" in stdouterrlog, stdouterrlog)
+
+        stdouterrlog = self.startHarvester(concurrency=-1)
+        self.assertTrue("Concurrency must be at least 1" in stdouterrlog, stdouterrlog)
+
+    def testCompleteInOnAttempt(self):
+        r = RepositoryData.read(self.repofilepath)
+        r.complete = 'true'
+        r.save(self.repofilepath)
+        stdouterrlog = self.startHarvester(repository=REPOSITORY, runOnce=False, waitForNothingToDo=True)
+        self.assertEquals(15, self.sizeDumpDir())
+        self.assertTrue("Repository will be completed in one attempt" in stdouterrlog, stdouterrlog)
+
+    def testHarvestingContinues4Ever(self):
+        stdouterrlog = self.startHarvester(repository=REPOSITORY, runOnce=False, waitForNothingToDo=True)
+        self.assertEquals(15, self.sizeDumpDir())
+
     def emptyDumpDir(self):
         system('rm %s/*' % self.dumpDir)
 
diff --unidirectional-new-file --recursive --unified '--exclude=*.so' '--exclude=*.o' '--exclude=.svn' '--exclude=*.pyc' '--exclude=deps.d' '--exclude=applied' version_0/test/integration/integrationtestcase.py /home/hendrik/development/meresco/meresco-harvester/workingsets/7.3.3-Edurep/version_1/test/integration/integrationtestcase.py
--- version_0/test/integration/integrationtestcase.py	2012-02-28 08:47:24.000000000 +0100
+++ version_1/test/integration/integrationtestcase.py	2012-03-05 10:14:31.000000000 +0100
@@ -31,7 +31,7 @@
 
 from __future__ import with_statement
 
-from os.path import isdir, join, abspath, dirname, basename
+from os.path import isdir, join, abspath, dirname, basename, isfile
 from os import system, listdir, makedirs
 from sys import stdout
 
@@ -90,26 +90,38 @@
             raise AttributeError(name)
         return getattr(self.state, name)
 
-    def startHarvester(self, repository=None, verbose=False):
+    def startHarvester(self, repository=None, concurrency=None, runOnce=True, verbose=False, waitForNothingToDo=False):
         stdoutfile = join(self.integrationTempdir, "stdouterr-harvester.log")
-        stdouterrlog = open(stdoutfile, 'w')
+        open(stdoutfile, 'w').write("")
+        stdouterrlog = open(stdoutfile, 'r+')
         if verbose:
             stdouterrlog = stdout
-        additionalArgs = ['--repository=%s'%repository] if repository else []
+        additionalArgs = ['--repository=%s' % repository] if repository is not None else []
+        additionalArgs += ['--concurrency=%s' % concurrency] if concurrency is not None else []
+        additionalArgs += ['--runOnce'] if runOnce else []
         harvesterProcessInfo = Popen(
             args=[join(binDir, "meresco-harvester"), "-d", "adomain", "--logDir=%s" % self.harvesterLogDir, "--stateDir=%s" % self.harvesterStateDir, "--saharaurl=http://localhost:%s" % self.helperServerPortNumber] + additionalArgs, 
             cwd=binDir,
             env={'PYTHONPATH': harvesterDir, 'LANG': 'en_US.UTF-8'},
             stdout=stdouterrlog,
             stderr=stdouterrlog)
-        waitpid(harvesterProcessInfo.pid, 0)
+        if not waitForNothingToDo:
+            waitpid(harvesterProcessInfo.pid, 0)
+        while waitForNothingToDo:
+            stdouterrlog.seek(0)
+            if 'Nothing to do!' in stdouterrlog.read():
+                kill(harvesterProcessInfo.pid, 2)
+                break
+            sleep(1)
         stdouterrlog.flush()
+        stdouterrlog.close()
+        return open(stdoutfile).read()
 
 class IntegrationState(object):
     def __init__(self, stateName, fastMode):
         self.stateName = stateName
         self._pids = []
-        self.integrationTempdir = '/tmp/mh-integrationtest-%s' % stateName 
+        self.integrationTempdir = '/tmp/integrationtest-meresco-harvester-%s' % stateName 
         system('rm -rf ' + self.integrationTempdir)
 
         self.helperServerPortNumber = PortNumberGenerator.next()
@@ -121,9 +133,10 @@
         self.harvesterStateDir = join(self.integrationTempdir, "state")
 
         copytree("integration-data", self.integrationTempdir)
-        fileSubstVars(join(self.integrationTempdir, "data", "SRUUPDATE.target"), helperServerPortNumber=self.helperServerPortNumber)
-        fileSubstVars(join(self.integrationTempdir, "data", "FILESYSTEM.target"), integrationTempdir=self.integrationTempdir)
-        fileSubstVars(join(self.integrationTempdir, "data", "adomain.integrationtest.repository"), helperServerPortNumber=self.helperServerPortNumber)
+        for f in listdir(join(self.integrationTempdir, "data")):
+            filepath = join(self.integrationTempdir, "data", f)
+            if isfile(filepath):
+                fileSubstVars(filepath, helperServerPortNumber=self.helperServerPortNumber, integrationTempdir=self.integrationTempdir)
         config = readConfig(join(examplesPath, 'harvester.config'))
         
         # test example config has neccessary parameters
diff --unidirectional-new-file --recursive --unified '--exclude=*.so' '--exclude=*.o' '--exclude=.svn' '--exclude=*.pyc' '--exclude=deps.d' '--exclude=applied' version_0/test/integration/mocksaharaget.py /home/hendrik/development/meresco/meresco-harvester/workingsets/7.3.3-Edurep/version_1/test/integration/mocksaharaget.py
--- version_0/test/integration/mocksaharaget.py	2012-02-28 08:47:24.000000000 +0100
+++ version_1/test/integration/mocksaharaget.py	2012-03-05 10:14:31.000000000 +0100
@@ -31,6 +31,7 @@
 from time import gmtime, strftime
 from slowfoot.wrappers import wrapp
 from slowfoot.binderytools import bind_string, bind_file
+from os import listdir
 
 def buildResponseDateXml():
     return """<responseDate>%s</responseDate>""" % strftime('%Y-%m-%dT%H:%M:%SZ', gmtime())
diff --unidirectional-new-file --recursive --unified '--exclude=*.so' '--exclude=*.o' '--exclude=.svn' '--exclude=*.pyc' '--exclude=deps.d' '--exclude=applied' version_0/test/timedprocesstest.py /home/hendrik/development/meresco/meresco-harvester/workingsets/7.3.3-Edurep/version_1/test/timedprocesstest.py
--- version_0/test/timedprocesstest.py	2012-02-28 08:47:24.000000000 +0100
+++ version_1/test/timedprocesstest.py	2012-03-05 10:14:31.000000000 +0100
@@ -35,6 +35,8 @@
 from cq2utils import CQ2TestCase
 from meresco.harvester.timedprocess import TimedProcess
 from os.path import join
+from os import waitpid
+from time import sleep
 
 class TimedProcessTest(CQ2TestCase):
 
@@ -42,15 +44,18 @@
         fd = open(self.tempfile,'w')
         try:
             fd.write("""import sys
-sys.exit(42)""")
+sys.exit(123)""")
         finally:
             fd.close()
 
         tp = TimedProcess()
-        exitstatus = tp.executeScript(['python2.5', self.tempfile], 10)
+        process = tp.executeScript(['python2.5', self.tempfile], 10)
+        while process.poll() is None:
+            sleep(0.1)
+        exitstatus = tp.stopScript(process)
         self.assertFalse(tp.wasTimeout())
         self.assertTrue(tp.wasSuccess())
-        self.assertEquals(42, exitstatus)
+        self.assertEquals(123, exitstatus)
     
     def testSuccessParameters(self):
         fd = open(self.tempfile,'w')
@@ -62,10 +67,14 @@
             fd.close()
 
         tp = TimedProcess()
-        tp.executeScript(['python2.5', self.tempfile, 'it','is','difficult'], 10)
+        process = tp.executeScript(['python2.5', self.tempfile, 'it','is','difficult'], 10)
+        while process.poll() is None:
+            sleep(0.1)
+        exitstatus = tp.stopScript(process)
         self.assertFalse(tp.wasTimeout())
         self.assertTrue(tp.wasSuccess())
         self.assertEquals('3', open(join(self.tempdir, 'output.txt')).read())
+        self.assertEquals(0, exitstatus)
 
     def testTimeout(self):
         fd = open(self.tempfile,'w')
@@ -77,7 +86,11 @@
             fd.close()
 
         tp = TimedProcess()
-        tp.executeScript(['python2.5', self.tempfile], 1)
+        process = tp.executeScript(['python2.5', self.tempfile], 1)
+        while process.poll() is None:
+            sleep(0.1)
+        exitstatus = tp.stopScript(process)
         self.assertTrue(tp.wasTimeout())
         self.assertFalse(tp.wasSuccess())
+        self.assertEquals(-9, exitstatus)
         
